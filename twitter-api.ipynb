{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Cursor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add your twitter keys\n",
    "Replace the CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET in the code below with your own credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "        'consumer_key':        'CONSUMER_KEY',\n",
    "        'consumer_secret':     'CONSUMER_SECRET',\n",
    "        'access_token_key':    'ACCESS_TOKEN',\n",
    "        'access_token_secret': 'ACCESS_TOKEN_SECRET'\n",
    "    }\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {\n",
    "    80676829: 'Krzysztof Bosak',\n",
    "    955239446: 'Władysław Kosiniak-Kamysz',\n",
    "    2280346687: 'Małgorzata Kidawa-Błońska',\n",
    "    1193947151971311618: 'Szymon Hołownia',\n",
    "    202086424: 'Andrzej Duda',\n",
    "    466781777: 'Robert Biedroń'}\n",
    "\n",
    "candidates_ids = [key for key in id_to_label.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily stats\n",
    "Get todays number of followers, following and tweets for every candidate and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_stats = 'daily-stats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_stats():\n",
    "    today = datetime.today().strftime('%d/%m/%Y')\n",
    "    candidates = [api.get_user(id = user_id) for user_id in candidates_ids]\n",
    "    idx = pd.MultiIndex.from_product([[user.id for user in candidates], [today]], names=['profile', 'date'])\n",
    "    col = ['followers', 'following', 'tweets']\n",
    "    df = pd.DataFrame(\n",
    "        [[user.followers_count, user.friends_count, user.statuses_count] for user in candidates],\n",
    "            idx, col)\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_stats_file():\n",
    "    loaded_data = pd.read_csv(daily_stats, sep='\\t').set_index(['profile', 'date'])\n",
    "    today = datetime.today().strftime('%d/%m/%Y')\n",
    "    if not today in loaded_data.index.levels[1]:\n",
    "        todays_stats = get_current_stats()\n",
    "        updated = pd.concat([loaded_data, todays_stats])\n",
    "        updated.to_csv(daily_stats, sep=\"\\t\")\n",
    "        print(\"Csv file updated for: \" + today)\n",
    "    print(\"Data is up to date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is up to date\n"
     ]
    }
   ],
   "source": [
    "# update_stats_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "DATE_FORMAT = \"%d/%m/%Y\"\n",
    "\n",
    "def get_tweets_from_period(user_id, from_date, till_date, save=False, replace=False):\n",
    "    tweets = []\n",
    "    start_date = datetime.strptime(from_date, DATE_FORMAT).date()\n",
    "    end_date = datetime.strptime(till_date, DATE_FORMAT).date()\n",
    "\n",
    "    # get tweets from API\n",
    "    for status in Cursor(api.user_timeline, id=user_id).items():\n",
    "        if status.created_at.date() > end_date:\n",
    "            continue\n",
    "        if status.created_at.date() < start_date:\n",
    "            break\n",
    "        if status.truncated:    \n",
    "            try :\n",
    "                status = api.get_status(status.id_str, tweet_mode='extended')\n",
    "            except tweepy.TweepError as error :\n",
    "                if(error.__dict__['api_code'] == 34):\n",
    "                    accountStatus = 'dead'\n",
    "                    print(\"...{} is dead\".format(status.id_str))\n",
    "                    continue\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            status.full_text = status.text\n",
    "        tweets.append(status)\n",
    "        \n",
    "    # tweets to data frame\n",
    "    col = ['id','user_id','date','created_at',\n",
    "           'is_retweet', 'is_quote', 'likes', 'retweets', \n",
    "           'hashtags', 'mentions','text'\n",
    "          ]\n",
    "    series_list = [pd.Series([\n",
    "            tweet.id,\n",
    "            tweet.user.id,\n",
    "            tweet.created_at.strftime(DATE_FORMAT),\n",
    "            str(tweet.created_at),\n",
    "            int(hasattr(tweet, \"retweeted_status\")),\n",
    "            int(tweet.is_quote_status),\n",
    "            tweet.favorite_count,\n",
    "            tweet.retweet_count,\n",
    "            ', '.join(hashtag['text'] for hashtag in tweet.entities['hashtags']),\n",
    "            ', '.join(user['screen_name'] for user in tweet.entities[\"user_mentions\"]),\n",
    "            tweet.full_text\n",
    "        ], index=col) for tweet in tweets]\n",
    "\n",
    "    df = pd.DataFrame(series_list)\n",
    "    df = df.replace(\"\", \"-\")\n",
    "    df = df.set_index('id')\n",
    "    if save:\n",
    "        file_name = \"{}-tweets.csv\".format(user_id)\n",
    "        if replace:\n",
    "            df.to_csv(file_name, sep=\"\\t\")\n",
    "        else:\n",
    "            saved_df = pd.read_csv(file_name, sep='\\t', index_col=0)\n",
    "            updated_df = pd.concat([df, saved_df]).reset_index().drop_duplicates(subset=['id']).set_index('id')\n",
    "            print(\"saved: {}, new: {}\".format(len(saved_df), len(updated_df)))\n",
    "            updated_df.to_csv(file_name, sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in candidates_ids:\n",
    "    get_tweets_from_period(user_id ,'10/04/2020', '14/04/2020', save=True, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cogsci-venv",
   "language": "python",
   "name": ".cogsci-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
